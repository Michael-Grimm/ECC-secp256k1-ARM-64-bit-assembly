
/*
Macro MUL_U256 multiplies two 256-bit unsigned integers.
The product is a 512-bit unsigned integer
product = multiplier x multiplicand
multiplier:    sa0...sa3 (sa0: least significant 64-bit integer)
multiplicand:  sb0...sb3 (sb0: least significant 64-bit integer)  
product:       sr0...sr7 (sr0: least significant...)          
Addition of partial products:

|  sr7   |  sr6   |  sr5   |   sr4  |  sr3   |  sr2   |  sr1   |  sr0   |
|-----------------------------------------------------------------------|
|        |        |        |        |        |        |sa0sb0hi|sa0sb0lo|
|        |        |        |        |        |sa1sb0hi|sa1sb0lo|        |    
|        |        |        |        |sa2sb0hi|sa2sb0lo|        |        |
|        |        |        |sa3sb0hi|sa3sb0lo|        |        |        |
|        |        |        |        |        |sa0sb1hi|sa0sb1lo|        |
|        |        |        |        |sa1sb1hi|sa1sb1lo|        |        |
|        |        |        |sa2sb1hi|sa2sb1lo|        |        |        |
|        |        |sa3sb1hi|sa3sb1lo|        |        |        |        |
|        |        |        |        |sa0sb2hi|sa0sb2lo|        |        |
|        |        |        |sa1sb2hi|sa1sb2lo|        |        |        |
|        |        |sa2sb2hi|sa2sb2lo|        |        |        |        |
|        |sa3sb2hi|sa3sb2lo|        |        |        |        |        |
|        |        |        |sa0sb3hi|sa0sb3lo|        |        |        |
|        |        |sa1sb3hi|sa1sb3lo|        |        |        |        |
|        |sa2sb3hi|sa2sb3lo|        |        |        |        |        |
|sa3sb3hi|sa3sb3lo|        |        |        |        |        |        |
|-----------------------------------------------------------------------|     
|  sr7   |  sr6   |  sr5   |  sr4   |  sr3   |  sr2   |  sr1   |  sr0   |
*/
.macro MUL_U256
        mov sr2, xzr
        mov sr3, xzr
        mov sr4, xzr
        mov sr5, xzr        
        mov sr6, xzr
        mov sr7, xzr     
           
        //sa0sb0 in sr1 sr0
        mul     sr0, sa0, sb0
        umulh   sr1, sa0, sb0
        //sa1sb0 in sr2 sr1
        mul     tmp5, sa1, sb0
        umulh   tmp4, sa1, sb0
        adds    sr1, sr1, tmp5
        adc     sr2, sr2, tmp4
        //sa2sb0 in sr3 sr2
        mul     tmp5, sa2, sb0
        umulh   tmp4, sa2, sb0
        adds    sr2, sr2, tmp5
        adc     sr3, sr3, tmp4
        //sa3sb0
        mul     tmp5, sa3, sb0
        umulh   tmp4, sa3, sb0
        adds    sr3, sr3, tmp5
        adc    sr4, sr4, tmp4
        
        //sa0sb1
        mul     tmp5, sa0, sb1
        umulh   tmp4, sa0, sb1
        adds     sr1, sr1, tmp5
        adcs     sr2, sr2, tmp4
        adcs     sr3, sr3, xzr
        adcs     sr4, sr4, xzr
        adc      sr5, sr5, xzr
        //sa1sb1
        mul     tmp5, sa1, sb1
        umulh   tmp4, sa1, sb1
        adds    sr2, sr2, tmp5
        adcs     sr3, sr3, tmp4
        adcs     sr4, sr4, xzr
        adc      sr5, sr5, xzr
        //sa2sb1
        mul     tmp5, sa2, sb1
        umulh   tmp4, sa2, sb1
        adds    sr3, sr3, tmp5
        adcs    sr4, sr4, tmp4
        adc     sr5, sr5, xzr
        //sa3sb1  
        mul     tmp5, sa3, sb1
        umulh   tmp4, sa3, sb1
        adds    sr4, sr4, tmp5
        adc     sr5, sr5, tmp4
        
        //sa0sb2 
        mul     tmp5, sa0, sb2
        umulh   tmp4, sa0, sb2
        adds    sr2, sr2, tmp5
        adcs     sr3, sr3, tmp4
        adcs     sr4, sr4, xzr
        adcs     sr5, sr5, xzr
        adc      sr6, sr6, xzr
        //sa1sb2
        mul     tmp5, sa1, sb2
        umulh   tmp4, sa1, sb2
        adds    sr3, sr3, tmp5
        adcs     sr4, sr4, tmp4
        adcs     sr5, sr5, xzr
        adc      sr6, sr6, xzr
        //sa2sb2
        mul     tmp5, sa2, sb2
        umulh   tmp4, sa2, sb2
        adds    sr4, sr4, tmp5
        adcs     sr5, sr5, tmp4
        adc      sr6, sr6, xzr
        //sa3sb2
        mul     tmp5, sa3, sb2
        umulh   tmp4, sa3, sb2
        adds    sr5, sr5, tmp5
        adc     sr6, sr6, tmp4
        
        //sa0sb3
        mul     tmp5, sa0, sb3
        umulh   tmp4, sa0, sb3
        adds    sr3, sr3, tmp5
        adcs     sr4, sr4, tmp4
        adcs     sr5, sr5, xzr
        adcs     sr6, sr6, xzr
        adc      sr7, sr7, xzr
        //sa1sb3
        mul     tmp5, sa1, sb3
        umulh   tmp4, sa1, sb3
        adds    sr4, sr4, tmp5
        adcs     sr5, sr5, tmp4
        adcs     sr6, sr6, xzr
        adc      sr7, sr7, xzr
        //sa2sb3
        mul     tmp5, sa2, sb3
        umulh   tmp4, sa2, sb3
        adds    sr5, sr5, tmp5
        adcs     sr6, sr6, tmp4
        adc      sr7, sr7, xzr
        //sa3sb3
        mul     tmp5, sa3, sb3
        umulh   tmp4, sa3, sb3
        adds    sr6, sr6, tmp5
        adc     sr7, sr7, tmp4
.endm

   


/*
Big integer squaring
Addition of the partial products
c: possible carry
sr7	     |sr6      |sr5      |sr4      |sr3      |sr2      |sr1      |sr0      |
-------------------------------------------------------------------------------|
         |         |	     |		   |         |         |sa0*sa0hi|sa0*sa0lo|
         |         |	     |		   |         |    c    |sa0*sa1lo|         |
         |         |	     |		   |         |    c    |sa0*sa1lo|         |
         |         |	     |		   |    c    |sa0*sa1hi|         |         |		
         |         |	     |		   |    c    |sa0*sa1hi|         |         |		
         |         |	     |		   |    c    |sa0*sa2lo|         |         |				
         |         |	     |	       |    c    |sa0*sa2lo|         |         |		
         |         |	     |		   |    c    |sa1*sa1lo|         |         |		
         |         |	     |    c    |sa0*sa2hi|         |         |         |		 
         |         |	     |    c    |sa0*sa2hi|         |         |         |		
         |         |	     |    c    |sa0*sa3lo|         |         |         |		 
         |         |	     |    c    |sa0*sa3lo|         |         |         |	
         |         |	     |    c    |sa1*sa1hi|         |         |         |	  	
         |         |	     |    c    |sa1*sa2lo|         |         |         |	  	
         |         |	     |    c    |sa1*sa2lo|         |         |         |		 			   		
         |         |	c    |sa0*sa3hi|         |         |         |         |		    		   	
         |         |	c    |sa0*sa3hi|         |         |         |         |		    		   		
         |         |	c    |sa1*sa2hi|         |         |         |         |		  			   		
         |         |	c    |sa1*sa2hi|         |         |         |         |		  			   		
         |         |	c    |sa1*sa3lo|         |         |         |         |		  			   		
         |         |	c    |sa1*sa3lo|         |         |         |         |		  			   		
         |         |	c    |sa2*sa2lo|         |         |         |         | 	     
         |    c    |sa1*sa3hi|         |         |         |         |         |		    
         |    c    |sa1*sa3hi|         |         |         |         |         |		    
         |    c    |sa2*sa2hi|         |         |         |         |         |		    
         |    c    |sa2*sa3lo|         |         |         |         |         |		     		   		
         |    c    |sa2*sa3lo|         |         |         |         |         |	    		   		
    c    |sa2*sa3hi|         |         |         |         |         |         |		    		   		
    c    |sa2*sa3hi|         |         |         |         |         |         |		    		   	 	
    c    |sa3*sa3lo|         |         |         |         |         |         |		    		   	 	
sa3*sa3hi|         |         |         |         |         |         |         |		    		   		
-------------------------------------------------------------------------------|
*/							

.macro SQUARE_U256   
        //sa0*sa0 in sr1 sr0
        mul   sr0, sa0, sa0
        umulh sr1, sa0, sa0
        //2*sa0*sa1 lo to sr1, carries in sr2
        mul   tmp5, sa0, sa1
        adds  sr1, sr1, tmp5
        adc   sr2, xzr, xzr
        adds  sr1, sr1, tmp5
        adc   sr2, sr2, xzr        
        //2*sa0*sa1 hi to sr2, carries in sr3
        umulh tmp5, sa0, sa1
        adds  sr2, sr2, tmp5
        adc   sr3, xzr, xzr
        adds  sr2, sr2, tmp5
        adc   sr3, sr3, xzr
        //2*sa0*sa2 lo to sr2
        mul   tmp5, sa0, sa2
        adds  sr2, sr2, tmp5
        adc   sr3, sr3, xzr
        adds  sr2, sr2, tmp5
        adc   sr3, sr3, xzr 
        //sa1*sa1 lo to sr2
        mul   tmp5, sa1, sa1
        adds  sr2, sr2, tmp5
        adc   sr3, sr3, xzr
        //2*sa0*sa2 hi to sr3, carries in sr4
        umulh tmp5, sa0, sa2
        adds  sr3, sr3, tmp5
        adc   sr4, xzr, xzr
        adds  sr3, sr3, tmp5
        adc   sr4, sr4, xzr
        //2*sa0*sa3 lo to sr3 
        mul   tmp5, sa0, sa3
        adds  sr3, sr3, tmp5
        adc   sr4, sr4, xzr
        adds  sr3, sr3, tmp5
        adc   sr4, sr4, xzr
        //sa1*sa1 hi to sr3
        umulh tmp5, sa1, sa1
        adds  sr3, sr3, tmp5
        adc   sr4, sr4, xzr   
        //2*sa1*sa2 lo to sr3 
        mul   tmp5, sa1, sa2
        adds  sr3, sr3, tmp5
        adc   sr4, sr4, xzr
        adds  sr3, sr3, tmp5
        adc   sr4, sr4, xzr 
        //2*sa0*sa3 hi to sr4, carries in sr5
        umulh tmp5, sa0, sa3
        adds  sr4, sr4, tmp5
        adc   sr5, xzr, xzr
        adds  sr4, sr4, tmp5
        adc   sr5, sr5, xzr               
        //2*sa1*sa2 hi to sr4
        umulh tmp5, sa1, sa2
        adds  sr4, sr4, tmp5
        adc   sr5, sr5, xzr
        adds  sr4, sr4, tmp5
        adc   sr5, sr5, xzr  
        //2*sa1*sa3 lo to sr4  
        mul   tmp5, sa1, sa3
        adds  sr4, sr4, tmp5
        adc   sr5, sr5, xzr
        adds  sr4, sr4, tmp5
        adc   sr5, sr5, xzr         
        //sa2*sa2 lo to sr4
        mul   tmp5, sa2, sa2
        adds  sr4, sr4, tmp5
        adc   sr5, sr5, xzr  
        //2*sa1*sa3 hi to sr5, carries in sr6
        umulh tmp5, sa1, sa3
        adds  sr5, sr5, tmp5
        adc   sr6, xzr, xzr
        adds  sr5, sr5, tmp5
        adc   sr6, sr6, xzr              
        //sa2*sa2 hi to sr5
        umulh tmp5, sa2, sa2
        adds  sr5, sr5, tmp5
        adc   sr6, sr6, xzr        
        //2*sa2*sa3 lo to sr5
        mul   tmp5, sa2, sa3
        adds  sr5, sr5, tmp5
        adc   sr6, sr6, xzr          
        adds  sr5, sr5, tmp5
        adc   sr6, sr6, xzr          
        //2*sa2*sa3 hi to sr6, carries in sr7
        umulh tmp5, sa2, sa3
        adds  sr6, sr6, tmp5
        adc   sr7, xzr, xzr
        adds  sr6, sr6, tmp5
        adc   sr7, sr7, xzr          
        //sa3*sa3 lo to sr6
        mul   tmp5, sa3, sa3
        adds  sr6, sr6, tmp5
        adc   sr7, sr7, xzr        
        //sa3*sa3 hi to sr7
        umulh tmp5, sa3, sa3
        adds  sr7, sr7, tmp5                       
.endm



















































