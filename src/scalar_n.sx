/*
Use of registers in functions modulo order n
 io0....io3 inputs from calling c-functions
 sa0....sa3 u256-integer a0...a3 as input for functions
 sb0...sb3 u256-integer b0...b3 as input for functions
sr0...sr7 u512-integer r0...r7 as result of multiplication of a*b
sr0...sr3 u256-integer r0...r3 as result of multiplication a*b mod n
on0...on3 n: 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEBAAEDCE6AF48A03BBFD25E8CD0364141
don1...don2 d = 2^256 - n = 0x1_4551231950b75fc4_402da1732fc9bebf
don1       0x0x402da1732fc9bebf 
don2       0x4551231950b75fc4   
tmp3...tmp5 free use
x29		  frame pointer
x30       procedure link register
*/


.section .rodata 

			.global secp256k1_n //Order of the curve
secp256k1_n:  // 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEBAAEDCE6AF48A03BBFD25E8CD0364141
            .quad 0xBFD25E8CD0364141, 0xBAAEDCE6AF48A03B, 0xFFFFFFFFFFFFFFFE, 0xFFFFFFFFFFFFFFFF

            .global secp256k1_n_half //Half of the order n, used for normalization of signature.s
secp256k1_n_half://0x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF5D576E7357A4501DDFE92F46681B20A0        
			.quad 0xdfe92f46681b20a0, 0x5d576e7357a4501d, 0xffffffffffffffff, 0x7fffffffffffffff  
   
            .global secp256k1_d
secp256k1_d: //0x14551231950b75fc4402da1732fc9bebf  n = 2^256 - d
            .quad 0x402da1732fc9bebf, 0x4551231950b75fc4, 1
            
.text

.include "aliases"
.include "commonmacros"
.include "u256macros"


/**
  Macro NORMALIZE_S is used for
  normalizing the s of a signature:
  see: secp256k1_ecdsa_signature_normalize  
  in https://github.com/bitcoin-core/secp256k1/blob/master/include/secp256k1.h
  if sig.s > n/2 ->  sig.s = n-sig.s
  Input:
  order n in on0...on3
  s in a (sa0...sa3)
  half order n/2 in b (sb0...sb3)
  Result: normalized s in a
*/
.macro NORMALIZE_S_IN_A
        cmp sa3, sb3
        bhi is_higher\@  //sa3>sb3-> goto is_higher
        blo end_normalize\@
        cmp sa2, sb2
        bhi is_higher\@
        blo end_normalize\@
        cmp sa1, sb1
        bhi is_higher\@
        blo end_normalize\@
        cmp sa0, sb0
        bhi is_higher\@
        //here s == n/2
        b end_normalize\@
      is_higher\@: //s>n/2 -> s = n - s
        subs sa0, on0, sa0
        sbcs sa1, on1, sa1
        sbcs sa2, on2, sa2
        sbc  sa3, on3, sa3  
      end_normalize\@:    
.endm



/**
  Wrapper function
*/
BEGIN_GLOBAL_FUNCTION normalize_s_in_a
        INIT_ORDER_N
        LOAD_B_WITH_HALF_N
		NORMALIZE_S_IN_A
END_GLOBAL_FUNCTION normalize_s_in_a


/**
  C-function for testing normalization of signature.s
  Input:
  io0 address of s
 */
BEGIN_C_FUNCTION secp256k1_normalize_s
    INIT_ORDER_N
    mov tmp5, io0
	LOAD_A tmp5
	LOAD_B_WITH_HALF_N
    NORMALIZE_S_IN_A
    STORE_A io0
END_C_FUNCTION secp256k1_normalize_s 
 
 
/*
The macro REDUCE_256_MOD_N
reduces a 256-bit-value x, if x>= order n.
Asigns the reduced value to x.
x is expected in sr0...sr3
The order is expected in on0...on3
Output:
in sr0...sr3
*/
.macro REDUCE_256_MOD_N  
        cmp sr3, on3
        blo is_lower\@ 
        bhi is_higher\@
        cmp sr2, on2
        blo is_lower\@
        bhi is_higher\@
        cmp sr1, on1
        blo is_lower\@
        bhi is_higher\@
        cmp sr0, on0
        blo is_lower\@
        //here x >= n
      is_higher\@: //x > order n -> subtract n
        subs sr0, sr0, on0
        sbcs sr1, sr1, on1
        sbcs sr2, sr2, on2
        sbc  sr3, sr3, on3  
      is_lower\@: //x < order n, do nothing
  
.endm



/**
  Expects the value to be reduced in r lo (sr0...sr3)
  Reduced value remains in r
*/
BEGIN_GLOBAL_FUNCTION reduce_r_mod_n
		INIT_ORDER_N
        REDUCE_256_MOD_N
END_GLOBAL_FUNCTION reduce_r_mod_n

.macro REDUCE_512_MOD_N
        reduce_r7\@:
        mul     tmp3, don1, sr7 //don1*r7 lo
        umulh   tmp4, don1, sr7 //don1*r7 hi
        mov     tmp5, sr7      //r7 in tmp5
        adds    sr3, sr3, tmp3 
        adcs    sr4, sr4, tmp4
        adcs    sr5, sr5, xzr
        adcs    sr6, sr6, xzr
        adc     sr7, xzr, xzr //new carry in sr7?
        
        mul     tmp3, don2, tmp5 //don2*r7 lo
        umulh   tmp4, don2, tmp5 //don2*r7 hi
        adds    sr4, sr4, tmp3 
        adcs    sr5, sr5, tmp4
        adcs    sr6, sr6, xzr
        adc     sr7, sr7, xzr
        
        adds    sr5, sr5, tmp5 //d2r7=r7
        adcs    sr6, sr6, xzr
        adc     sr7, sr7, xzr
        cbnz sr7, reduce_r7\@
   
        reduce_r6\@:
        mul     tmp3, don1, sr6 //don1*r6 lo
        umulh   tmp4, don1, sr6 //don1*r6 hi
        mov     tmp5, sr6      //r6 in tmp5
        adds    sr2, sr2, tmp3 
        adcs    sr3, sr3, tmp4
        adcs    sr4, sr4, xzr
        adcs    sr5, sr5, xzr
        adc     sr6, xzr, xzr 
        
        mul     tmp3, don2, tmp5 //don2*r6 lo
        umulh   tmp4, don2, tmp5 //don2*r6 hi
        adds    sr3, sr3, tmp3 
        adcs    sr4, sr4, tmp4
        adcs    sr5, sr5, xzr
        adc     sr6, sr6, xzr
        
        adds    sr4, sr4, tmp5 //d2r6=r6
        adcs    sr5, sr5, xzr
        adc     sr6, sr6, xzr 
        cbnz sr6, reduce_r6\@   //new carries in sr6?

        reduce_r5\@:
        mul     tmp3, don1, sr5 //don1*r5 lo
        umulh   tmp4, don1, sr5 //don1*r5 hi
        mov     tmp5, sr5      //r5 in tmp5
        adds    sr1,  sr1,  tmp3 
        adcs    sr2, sr2, tmp4
        adcs    sr3, sr3, xzr
        adcs    sr4, sr4, xzr
        adc     sr5, xzr, xzr 
        
        mul     tmp3, don2, tmp5 //don2*r5 lo
        umulh   tmp4, don2, tmp5 //don2*r5 hi
        adds    sr2, sr2, tmp3 
        adcs    sr3, sr3, tmp4
        adcs    sr4, sr4, xzr
        adc     sr5, sr5, xzr
        
        adds    sr3, sr3, tmp5 //d2r5=r5
        adcs    sr4, sr4, xzr
        adc     sr5, sr5, xzr 
        cbnz sr5, reduce_r5\@   //new carries in sr5?

        reduce_r4\@:
        mul     tmp3, don1, sr4 //don1*r4 lo
        umulh   tmp4, don1, sr4 //don1*r4 hi
        mov     tmp5, sr4      //r4 in tmp5
        adds    sr0, sr0, tmp3 
        adcs    sr1, sr1, tmp4
        adcs    sr2, sr2, xzr
        adcs    sr3, sr3, xzr
        adc     sr4, xzr, xzr 
        
        mul     tmp3, don2, tmp5 //don2*r4 lo
        umulh   tmp4, don2, tmp5 //don2*r4 hi
        adds    sr1, sr1, tmp3 
        adcs    sr2, sr2, tmp4
        adcs    sr3, sr3, xzr
        adc     sr4, sr4, xzr
        
        adds    sr2, sr2, tmp5 //d2r4=r4
        adcs    sr3, sr3, xzr
        adc     sr4, sr4, xzr 
        cbnz sr4, reduce_r4\@   //new carries in sr4?

        REDUCE_256_MOD_N 
.endm


/*
Macro ADD_A_B_MOD_N
Modular Addition modulo a prime (p or order n)
r = (a + b) mod n
a in sa0...sa3
b in sb0...sb3
r in sr0...sr3
The prime is expected in on0...on3
*/ 
.macro ADD_A_B_MOD_N
        adds   sr0, sa0, sb0
        adcs   sr1, sa1, sb1
        adcs   sr2, sa2, sb2
        adcs   sr3, sa3, sb3
        adc    sr4, xzr, xzr  
        cbz sr4, possibly_reduce_\@
		    carry_occured_\@: 
		    subs   sr0, sr0, on0
		    sbcs   sr1, sr1, on1
		    sbcs   sr2, sr2, on2
		    sbcs   sr3, sr3, on3
		    adc    sr4, xzr, xzr
		    cbnz sr4, carry_occured_\@ //this is possible if a > prime and b > prime
        possibly_reduce_\@: //reduces if sum >= prime
        	REDUCE_256_MOD_N   
.endm

/** Global functions for addition modulo n */
BEGIN_GLOBAL_FUNCTION add_a_b_mod_n
       INIT_ORDER_N
       ADD_A_B_MOD_N
END_GLOBAL_FUNCTION add_a_b_mod_n


BEGIN_GLOBAL_FUNCTION add_a_b_mod_n_asign_a
	   INIT_ORDER_N
       ADD_A_B_MOD_N
       COPY_R_LO_TO_A
END_GLOBAL_FUNCTION add_a_b_mod_n_asign_a

BEGIN_GLOBAL_FUNCTION add_a_b_mod_n_asign_b
	   INIT_ORDER_N
       ADD_A_B_MOD_N
       COPY_R_LO_TO_B
END_GLOBAL_FUNCTION add_a_b_mod_n_asign_b

/*
 The public C compatible function secp256k1_add_mod_n adds two scalars a + b
 modulo n.
 r = (a + b) mod n
 Address of scalar a in io0
 Address of scalar b in io1
 Address of result r in io2
*/
BEGIN_C_FUNCTION secp256k1_add_mod_n  
        INIT_ORDER_N   
        LOAD_A_B
        ADD_A_B_MOD_N
        STORE_R_LO io2
END_C_FUNCTION secp256k1_add_mod_n  


/*
Macro SUB_A_B_MOD_N
Modular subtraction modulo a prime (p or order n)
r = (a - b) mod n
a in sa0...sa3
b in sb0...sb3
r in sr0...sr3
The prime is expected in on0...on3
*/
.macro SUB_A_B_MOD_N
        subs   sr0, sa0, sb0
        sbcs   sr1, sa1, sb1
        sbcs   sr2, sa2, sb2
        sbcs   sr3, sa3, sb3
        sbc    sr4, xzr, xzr 
        cbz sr4, possibly_reduce\@
        //carry occured -> add n and ignore carry
		    adds   sr0, sr0, on0
		    adcs   sr1, sr1, on1
		    adcs   sr2, sr2, on2
		    adc    sr3, sr3, on3
        b endsubmod\@
        possibly_reduce\@:
        REDUCE_256_MOD_N
        endsubmod\@:
.endm

/** wrapper functions */
BEGIN_GLOBAL_FUNCTION sub_a_b_mod_n
	   INIT_ORDER_N
       SUB_A_B_MOD_N
END_GLOBAL_FUNCTION sub_a_b_mod_n

BEGIN_GLOBAL_FUNCTION sub_a_b_mod_n_asign_a
	   INIT_ORDER_N
       SUB_A_B_MOD_N
       COPY_R_LO_TO_A
END_GLOBAL_FUNCTION sub_a_b_mod_n_asign_a

BEGIN_GLOBAL_FUNCTION sub_a_b_mod_n_asign_b
	   INIT_ORDER_N
       SUB_A_B_MOD_N
       COPY_R_LO_TO_B
END_GLOBAL_FUNCTION sub_a_b_mod_n_asign_b

/*
 The public C compatible function secp256k1_sub_mod_n subtracts  a - b
 modulo n.
 r = (a - b) mod n
 Address of scalar a in io0
 Address of scalar b in io1
 Address of result r in io2
*/
BEGIN_C_FUNCTION secp256k1_sub_mod_n  
        INIT_ORDER_N   
        LOAD_A_B
        SUB_A_B_MOD_N
        STORE_R_LO io2
END_C_FUNCTION secp256k1_sub_mod_n


/**
 The public C-function secp256k1_reduce_mod_n reduces scalar a modulo order n.
 Address of scalar a in io0, reduced value in io0.
 a = a if a<n
 a = a - n if a>= n
*/
BEGIN_C_FUNCTION secp256k1_reduce_mod_n 
        INIT_ORDER_N
        //load scalar (address in io0) into sr0-sr3
        mov tmp5, io0
        ldp sr0, sr1, [tmp5], #16
        ldp sr2, sr3, [tmp5]
        REDUCE_256_MOD_N 
        STORE_R_LO io0
END_C_FUNCTION secp256k1_reduce_mod_n          


/**
 Global functions for multiplication modulo n
 multiplyer and multiplicand in a and b
*/
BEGIN_GLOBAL_FUNCTION mul_a_b_mod_n_asign_b
        INIT_ORDER_N
        MUL_U256
        REDUCE_512_MOD_N
        COPY_R_LO_TO_B
END_GLOBAL_FUNCTION mul_a_b_mod_n_asign_b

BEGIN_GLOBAL_FUNCTION mul_a_b_mod_n_asign_a
        INIT_ORDER_N
        MUL_U256
        REDUCE_512_MOD_N
        COPY_R_LO_TO_A
END_GLOBAL_FUNCTION mul_a_b_mod_n_asign_a
 
     
        
/**
Function secp256k1_mul_mod_n
multiplies two 256-bit integers modulo n.
n is the order of secp256k1: n = 2^256 - d
with d of n = 0x14551231950b75fc4402da1732fc9bebf
don0: 0x1 (no register needed)
don1: 0x402da1732fc9bebf
don2: 0x4551231950b75fc4

Input:
Result r = a*b (mod n)
Address of a: in io0
Address of b: in io1
Address of r: in io2
*/
BEGIN_C_FUNCTION secp256k1_mul_mod_n
        LOAD_A_B      
        MUL_U256
        INIT_ORDER_N
        REDUCE_512_MOD_N
        STORE_R_LO io2
END_C_FUNCTION secp256k1_mul_mod_n




/** Internal functions */
BEGIN_GLOBAL_FUNCTION square_a_mod_n
        SQUARE_U256
        REDUCE_512_MOD_N
END_GLOBAL_FUNCTION square_a_mod_n

BEGIN_GLOBAL_FUNCTION square_a_mod_n_asign_a
        SQUARE_U256
        REDUCE_512_MOD_N
        COPY_R_LO_TO_A
END_GLOBAL_FUNCTION square_a_mod_n_asign_a

BEGIN_GLOBAL_FUNCTION square_a_mod_n_asign_b
        SQUARE_U256
        REDUCE_512_MOD_N
        COPY_R_LO_TO_B
END_GLOBAL_FUNCTION square_a_mod_n_asign_b

/** Public C functions */
BEGIN_C_FUNCTION secp256k1_square_mod_n
        INIT_ORDER_N
        LOAD_A
        SQUARE_U256
        REDUCE_512_MOD_N
        STORE_R_LO io1
END_C_FUNCTION secp256k1_square_mod_n

BEGIN_C_FUNCTION secp256k1_square_mod_n_asign
        INIT_ORDER_N
        LOAD_A
        SQUARE_U256
        REDUCE_512_MOD_N
        STORE_R_LO io0
END_C_FUNCTION secp256k1_square_mod_n_asign

/*
Macros for the functions that use the same exponentiation algorithm but
with different exponents.
*/
.macro BIT0   //(exp & 1 != 1)
        bl square_a_mod_n_asign_a
.endm
.macro BIT1   //(exp & 1 == 1)
        bl mul_a_b_mod_n_asign_b
        bl square_a_mod_n_asign_a  
.endm
.macro NIB0   //0x0
        BIT0
        BIT0
        BIT0
        BIT0
.endm
.macro NIB1   //0x1
        BIT1
        BIT0
        BIT0
        BIT0
.endm
.macro NIB2   //0x2
        BIT0
        BIT1
        BIT0
        BIT0
.endm
.macro NIB3   //0x3
        BIT1
        BIT1
        BIT0
        BIT0
.endm
.macro NIB4   //0x4
        BIT0
        BIT0
        BIT1
        BIT0
.endm
.macro NIB5   //0x5
        BIT1
        BIT0
        BIT1
        BIT0
.endm
.macro NIB6   //0x6
        BIT0
        BIT1
        BIT1
        BIT0
.endm
.macro NIB7   //0x7
        BIT1
        BIT1
        BIT1
        BIT0
.endm
.macro NIB8   //0x8
        BIT0
        BIT0
        BIT0
        BIT1
.endm
.macro NIB9   //0x9
        BIT1
        BIT0
        BIT0
        BIT1
.endm
.macro NIBa   //0xa
        BIT0
        BIT1
        BIT0
        BIT1
.endm
.macro NIBb  //0xb
        BIT1
        BIT1
        BIT0
        BIT1
.endm
.macro NIBc  //0xc
        BIT0
        BIT0
        BIT1
        BIT1
.endm
.macro NIBd  //0xd
        BIT1
        BIT0
        BIT1
        BIT1
.endm
.macro NIBe //0xe
        BIT0
        BIT1
        BIT1
        BIT1
.endm
.macro NIBf   //0xf
        BIT1
        BIT1
        BIT1
        BIT1
.endm
.macro BYTEff //ff
        NIBf
        NIBf
.endm

.macro BYTEfe //fe
        NIBe
        NIBf
.endm
.macro QUADfe //0xFFFFFFFFFFFFFFFE
        BYTEfe 
        BYTEff 
        BYTEff 
        BYTEff 
        BYTEff 
        BYTEff 
        BYTEff 
        BYTEff        
.endm

.macro QUADX  //fffffffefffffc2d
        NIBd
        NIB2
        NIBc
        NIBf
        BYTEff
        BYTEff
        NIBe
        NIBf
        BYTEff
        BYTEff        
        BYTEff        
.endm

.macro QUADY //0xFFFFFFFFBFFFFF0C
        NIBc
        NIB0
        BYTEff
        BYTEff
        NIBf
        NIBb
        BYTEff
        BYTEff
        BYTEff
        BYTEff        
.endm 

.macro QUADZ //ffffffff7ffffe17
        NIB7
        NIB1
        NIBe
        BYTEff
        BYTEff
        NIB7
        BYTEff
        BYTEff
        BYTEff
        BYTEff                
.endm


.macro QUADff
        BYTEff 
        BYTEff 
        BYTEff 
        BYTEff 
        BYTEff 
        BYTEff 
        BYTEff 
        BYTEff 
.endm
.macro QUAD3f
        BYTEff 
        BYTEff 
        BYTEff 
        BYTEff 
        BYTEff 
        BYTEff 
        BYTEff 
        NIBf
        NIB3 
.endm 
.macro QUAD7f
        BYTEff 
        BYTEff 
        BYTEff 
        BYTEff 
        BYTEff 
        BYTEff 
        BYTEff 
        NIBf
        NIB7 
.endm 
.macro QUADN0 //bfd25e8cd036413f
       NIBf
       NIB3
       NIB1
       NIB4
       NIB6
       NIB3
       NIB0
       NIBd
       NIBc
       NIB8
       NIBe
       NIB5
       NIB2
       NIBd
       NIBf
       NIBb
.endm
.macro QUADN1 //baaedce6af48a03b
       NIBb
       NIB3
       NIB0
       NIBa
       NIB8
       NIB4
       NIBf
       NIBa
       NIB6
       NIBe
       NIBc
       NIBd
       NIBe
       NIBa
       NIBa
       NIBb
.endm


/*
Macro INVERT_A_MOD_N_INTO_B
calculates the inverse of scalar a modulo n 
b = inv a = a^-1 = a^n-2 (mod n)
--> a*b = a*(inv a) = 1
Input
a: sa0 sa1 sa2 sa3 
Result
b: sb0 sb1 sb2 sb3  

Algorithm (all functions are modulo n): 
exp=0xfffffffffffffffffffffffffffffffebaaedce6af48a03bbfd25e8cd036413f //n-2
b = 1 //The result
for(int i = 0; i<256; i++){
   if (exp & 1 == 1){
            b = b * a mod n;    
   }
   a = a * a mod n;             
   exp = exp >> 1;
}
In INVERT_A_MOD_N_INTO_B the for-loop, anding and shifting of the exponent (n-2) are 
unrolled using the macros above.
*/

.macro INVERT_A_MOD_N_INTO_B
        SET_B_TO_1
        QUADN0
        QUADN1
        QUADfe
        QUADff
.endm

/** wrapper function */
BEGIN_GLOBAL_FUNCTION invert_a_mod_n_into_b
        INIT_ORDER_N
        INVERT_A_MOD_N_INTO_B
END_GLOBAL_FUNCTION invert_a_mod_n_into_b

/** C function */
BEGIN_C_FUNCTION secp256k1_invert_mod_n
        INIT_ORDER_N
        LOAD_A
        INVERT_A_MOD_N_INTO_B
        STORE_B io1
END_C_FUNCTION secp256k1_invert_mod_n

/** C function */
BEGIN_C_FUNCTION secp256k1_invert_mod_n_asign
        INIT_ORDER_N
        LOAD_A
        INVERT_A_MOD_N_INTO_B
        STORE_B io0
END_C_FUNCTION secp256k1_invert_mod_n_asign        
        
